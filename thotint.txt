3V’s of big data
Volume 
High volume  ‐ refers to the amount of data that is generated. The volume of big data overwhelms the 
normal data warehouse.
-> Amout of data generated
-> Online & offline transations
-> in kilobytes or terabytes
-> Saved in records, tables,files

Variety 
High variety ‐ refers to the types of data that is generated, in particular heterogeneous sources and the 
nature of data. This allows you  to collect and  organize data sets that do not relate to each other putting 
them together in one place and allow data experts to analyse and detect patterns and insights that you would not have seen otherwise.
->Structured and unstructured
->Online images and Videos
->Human generated-texts 
->Machine generated- readings 

Velocity 
High velocity ‐ refers to the speed at which data is generated. This allows companies to be immediate and 
reactive, Companies not only have to master the huge volumes and variety but also have to deal with the 
speed of data generation
-> Speed of generating data
-> Generated in real-time
-> Online and Offline data
-> In Streams, batch or bits

Big data value chain 
The data acquisition activity is the process of gathering, filtering and cleaning data before it is put in a data 
warehouse or any other storage solution on which data analysis can be carried out (Curry, 2016). 

Data analysis is concerned with making the raw data acquired amenable to use in decision‐making as well 
as domain‐specific usage (Curry, 2016). 

Data curation is the active management of data over its lifecycle to ensure it meets the necessary data 
quality requirements for its effective usage (Curry, 2016). 

Data  storage is  the  persistence and management  of  data in a  scalable way  that  satisfies  the  needs  of 
applications that require fast access to the data (Curry, 2016). 

Data usage covers the data‐driven business activities that need access to data, its analysis and the tools 
needed to integrate the data analysis within the business activity. 

Non‐relational database technologies have the following common characteristics: 
 Scalability – capability to write data across multiple data store concurrently 
 Data and query model – use specialty frameworks to store data with a requisite set of specialty 
query APIs to intelligently access data 
 Persistence design – due to high volume, velocity and variety of big data these databases use 
different mechanisms for persisting data 
 Interface diversity – even as most of these technologies use RESTful APIs as their default 
interface they will give you the option of numerous types of connection devices for 
programmers and database managers, including analysis tools and reporting 
 Eventual consistency – while RDBMS uses ACID as a device for making sure data is consistent, 
non‐relational DBMS use BASE. BASE stands for Basically Available, Soft State and Eventual 
Consistency. Eventual consistency is in charge of conflict resolution when data is in motion 
between nodes.

Types of big data 
There are three types of big data, namely structured, semi‐structured and unstructured. 
Structured data is data that can be stored or processed in a fixed format. For example, a table in a 
database has a fixed format and structure. 
Semi‐structured  data  is  a  form  of  structured  data  that  has  tags  or  markers  to  identify  elements.  For 
example, XML or JSON is semi‐structured. 
Unstructured data has internal structure but cannot be defined via models or a schema. This data can 
come  from  sources  such as Facebook, Twitter and  video  content. This  data is  random and  difficult  to 
analyse.

Big data analytics
Basic analytics 
In basic analytics you can explore your data especially if you know you have valuable data but are unsure 
of its value. This might include simple visualisations or simple statistics. Basic analytics is often used for 
large amounts of dissimilar data. 
Slicing and dicing 
Slicing and dicing refers to breaking down your data into smaller sets so that they are easier to search 
through. 
Basic monitoring 
You might consider monitoring large volumes of data in real time 
Anomaly identification 
You could also identify irregularities such as an occurrence where actual observation is different  from 
what you expected in your data. 
Advanced analytics 
When you move toward advanced analytics you would have to deal with algorithms for complex analysis 
of  either  structured  or  unstructured  data.  You  would  need  sophisticated  statistical  models,  machine 
learning, neural networks, text analytics and other advanced data‐mining techniques. Advanced analytics 
can be deployed to find patterns in data, prediction, forecasting and complex event processing.  
Predictive modelling 
Predictive modelling is a statistical or data‐mining solution that consists of algorithms and techniques used 
on both structured and unstructured data (together or individually) to determine future outcomes. 
Text analytics 
This is the process of analysing unstructured text, extracting relevant information and transforming it 
into structured information that can then be leveraged in many ways. 

Three classes of technology that can store and manage big data are: 
 NewSQL – a form of relational databases that aim to scale as easily as NoSQL databases 
 NoSQL – these use data modules from outside the relational world that do not necessarily 
adhere to ACID 
 Distributed file systems such as Hadoop file system 
 Massive Parallel Processing (MPP)  

JSON 
What is JSON? 
JSON  stands  for  JavaScript Object Notation and is a  standard  text‐based  format  for  representing  data 
based on JavaScript object syntax. Although it closely resembles JavaScript, it can be used independently 
of JavaScript. Many NoSQL databases uses JSON to query data. 
JSON exists as a string and needs to be converted to a native JavaScript object when you want to access 
data. 

NoSQL 
NoSQL stands for Not Only SQL and is among the best technologies for handling large amounts of data. 
NoSQL is a non‐relational DBMS that does not require a schema, avoids joins and scales easily. These data 
stores provide domain‐specific access and query techniques in addition to SQL or SQL‐like interfaces. 
Characteristics of NoSQL databases 
 Distributed computing 
These  databases  are  distributed,  can  scale  horizontally  and  handle  volumes  of  data  with  low  latency. 
NoSQL databases use clusters, groups of computers to store and support database operations. Therefore, 
horizontal scaling, adding more nodes to the distributed database, is possible with these databases.  
 More flexible data model 
NoSQL databases are not  relational. Instead  they  use  flexible  data models  such as key‐value  stores or 
document stores. The types of NoSQL databases will be discussed in more detail in a later section. 
 Asynchronous inserts and updates 
Full transactional guarantees and simultaneous completion of transactions at all nodes in the distributed 
environment are not provided by NoSQL databases. Instead it guarantees the availability of the data at 
the distributed level (by some internal process of synchronization). 
 Query language 
NoSQL databases can support SQL‐like query languages and some have support additional languages like 
JSON to store data or JavaScript as a query language. 
 No Joins 
NoSQL databases do not support conventional joins 
 Low Cost 
As previously mentioned, they make use of clusters. These clusters are comprised of commodity servers 
and not proprietary servers. 
 Easy implementation 
They provide flexible schemas and less complicated relationships than a relational database.

Advantages of NoSQL databases 
Data models 
NoSQL databases leverage data models  to  suit  the  specific use  case, making  them more  suitable  than 
relational databases. For example, key‐value databases support simple queries very efficiently while graph 
databases are the best for queries that involve identifying complex relationships between separate pieces 
of data. 
Performance 
No SQL databases often perform better than relational databases in terms of query performance as well 
as development time. For example, data required to service a query might only need to be retrieved from 
a single place instead of requiring multiple joins as with a relational database. 
Scalability 
While  SQL  databases  were  intended  to  be  scalable,  the  scalability  options  are  often  expensive  and 
complicated. With NoSQL databases, the design was meant to scale out horizontally from the start and 
performance is easily maintained as you are not limited to a single server. 
Data distribution 
NoSQL  databases are  designed  from  the  ground  up  as  distributed databases  and  can  therefore easily 
support a variety of different business requirements. 
Reliability 
NoSQL databases ensure high availability and uptime with native replication and built‐in failover for self‐
healing, resilient database clusters. Similar failover systems can be set up for SQL databases but since the 
functionality is not native  to  the underlying database,  this often means more  resources  to deploy and 
maintain  a  separate  clustering  layer  that  then  takes  longer  to  identify  and  recover  from  underlying 
systems failures. 
Flexibility 
NoSQL databases are better at allowing users to test new ideas and update data structures. For example, 
MongoDB, the leading document database, stores data in flexible, JSON‐like documents, meaning fields 
can  vary  from  document  to  document  and  the  data  structures  can  be  easily  changed  over  time,  as 
application  requirements  evolve.  This  is  a  better  fit  for  modern  microservices  architectures  where 
developers are continuously integrating and deploying new application functionality. 

Disadvantages of NoSQL databases 
The disadvantages of NoSQL databases are: 
 Too many options 
 Limited query capabilities 
 Eventual consistency is not intuitive to programme for strict scenarios like banking applications 
 Lacks joins, group by, order by facilities 
 ACID transactions 
 Limited guarantee of support due to being open source 

Types of NoSQL databases 
There are four types of NoSQL databases: 
 Key‐value stores 
 Document‐based store 
 Column‐based store 
 Graph‐based

ACID (Atomicity, Consistency, Isolation, Durability):

ACID is a set of properties that guarantee the reliable processing of database transactions. Here's a brief explanation of each component:

Atomicity: This property ensures that a transaction is treated as a single, indivisible unit. Either all the changes within a transaction are applied, or none of them are. If any part of the transaction fails, the entire transaction is rolled back to its previous state.

Consistency: Consistency guarantees that a transaction brings the database from one valid state to another. It enforces predefined rules and constraints, ensuring that the data remains accurate and follows the intended business rules.

Isolation: Isolation ensures that multiple concurrent transactions do not interfere with each other. Each transaction should appear to run in isolation, even when multiple transactions are executed simultaneously. Isolation levels, such as Read Committed or Serializable, control the level of isolation between transactions.

Durability: Durability guarantees that once a transaction is committed, its changes are permanent and will survive any system failures (e.g., power outage or hardware failure). Data changes are stored persistently, typically in non-volatile storage like disk.

CAP Theorem (Consistency, Availability, Partition Tolerance):

The CAP theorem is a concept in distributed computing that states that it's impossible for a distributed system to simultaneously achieve all three of the following attributes:

Consistency: Every read operation in the system returns the most recent write operation's value. In other words, all nodes in the system see the same data.

Availability: Every request (read or write) made to the system receives a response, without guaranteeing that it contains the most recent data.

Partition Tolerance: The system continues to function correctly even when network partitions (communication failures) occur between nodes, meaning some nodes are unable to communicate with each other.

The CAP theorem suggests that in a distributed system, you can achieve at most two out of these three attributes simultaneously. For example:

If you prioritize Consistency and Availability, your system may not be tolerant of network partitions (CA).
If you prioritize Availability and Partition Tolerance, you may have eventual consistency, meaning data might not be immediately consistent across all nodes (AP).
If you prioritize Consistency and Partition Tolerance, you may sacrifice immediate availability in certain scenarios (CP).
BASE (Basically Available, Soft State, Eventually Consistent):

BASE is an alternative approach to distributed system design that contrasts with the strict consistency model of ACID. Here's a brief explanation of each component:

Basically Available: This means the system remains operational most of the time, but it doesn't guarantee 100% availability. It acknowledges that there may be temporary failures or inconsistencies.

Soft State: Unlike the rigid consistency model of ACID, BASE allows for soft states where data might be inconsistent for a short period. Soft state acknowledges that during system transitions, data can be in an intermediate or changing state.

Eventually Consistent: BASE systems prioritize eventual consistency over immediate consistency. In other words, the data will eventually become consistent across all nodes, but there may be a delay or temporary inconsistency.

BASE is often chosen for distributed systems that can tolerate some level of inconsistency or are more focused on high availability and partition tolerance, as opposed to strict consistency like ACID systems